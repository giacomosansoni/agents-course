{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Solving a complex task with a multi-agent hierarchy\n",
    "\n",
    "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
    "\n",
    "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
    "\n",
    "The reception is approaching! With your help, Alfred is now nearly finished with the preparations.\n",
    "\n",
    "But now there's a problem: the Batmobile has disappeared. Alfred needs to find a replacement, and find it quickly.\n",
    "\n",
    "Fortunately, a few biopics have been done on Bruce Wayne's life, so maybe Alfred could get a car left behind on one of the movie set, and re-engineer it up to modern standards, which certainly would include a full self-driving option.\n",
    "\n",
    "But this could be anywhere in the filming locations around the world - which could be numerous.\n",
    "\n",
    "So Alfred wants your help. Could you build an agent able to solve this task?\n",
    "\n",
    "> üëâ Find all Batman filming locations in the world, calculate the time to transfer via boat to there, and represent them on a map, with a color varying by boat transfer time. Also represent some supercar factories with the same boat transfer time.\n",
    "\n",
    "Let's build this!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install 'smolagents[litellm]' plotly geopandas shapely kaleido -q"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# We first make a tool to get the cargo plane transfer time.\n",
    "import math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from smolagents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_cargo_travel_time(\n",
    "    origin_coords: Tuple[float, float],\n",
    "    destination_coords: Tuple[float, float],\n",
    "    cruising_speed_kmh: Optional[float] = 750.0,  # Average speed for cargo planes\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the travel time for a cargo plane between two points on Earth using great-circle distance.\n",
    "\n",
    "    Args:\n",
    "        origin_coords: Tuple of (latitude, longitude) for the starting point\n",
    "        destination_coords: Tuple of (latitude, longitude) for the destination\n",
    "        cruising_speed_kmh: Optional cruising speed in km/h (defaults to 750 km/h for typical cargo planes)\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated travel time in hours\n",
    "\n",
    "    Example:\n",
    "        >>> # Chicago (41.8781¬∞ N, 87.6298¬∞ W) to Sydney (33.8688¬∞ S, 151.2093¬∞ E)\n",
    "        >>> result = calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093))\n",
    "    \"\"\"\n",
    "\n",
    "    def to_radians(degrees: float) -> float:\n",
    "        return degrees * (math.pi / 180)\n",
    "\n",
    "    # Extract coordinates\n",
    "    lat1, lon1 = map(to_radians, origin_coords)\n",
    "    lat2, lon2 = map(to_radians, destination_coords)\n",
    "\n",
    "    # Earth's radius in kilometers\n",
    "    EARTH_RADIUS_KM = 6371.0\n",
    "\n",
    "    # Calculate great-circle distance using the haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = (\n",
    "        math.sin(dlat / 2) ** 2\n",
    "        + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    )\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    distance = EARTH_RADIUS_KM * c\n",
    "\n",
    "    # Add 10% to account for non-direct routes and air traffic controls\n",
    "    actual_distance = distance * 1.1\n",
    "\n",
    "    # Calculate flight time\n",
    "    # Add 1 hour for takeoff and landing procedures\n",
    "    flight_time = (actual_distance / cruising_speed_kmh) + 1.0\n",
    "\n",
    "    # Format the results\n",
    "    return round(flight_time, 2)\n",
    "\n",
    "\n",
    "print(calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093)))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For the model provider, we use Together AI, one of the new [inference providers on the Hub](https://huggingface.co/blog/inference-providers)!\n",
    "\n",
    "Regarding the GoogleSearchTool: this requires either having setup env variable `SERPAPI_API_KEY` and passing `provider=\"serpapi\"` or having `SERPER_API_KEY` and passing `provider=serper`.\n",
    "\n",
    "If you don't have any Serp API provider setup, you can use `DuckDuckGoSearchTool` but beware that it has a rate limit."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from smolagents import CodeAgent, GoogleSearchTool, HfApiModel, VisitWebpageTool\n",
    "\n",
    "\n",
    "model = HfApiModel(model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"together\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can start with creating a baseline, simple agent to give us a simple report."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "task = \"\"\"Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128¬∞ N, 74.0060¬∞ W), and return them to me as a pandas dataframe.\n",
    "Also give me some supercar factories with the same cargo plane transfer time.\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"] = userdata.get('SERPAPI_API_KEY')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "agent = CodeAgent(\n",
    "    model=model,\n",
    "    tools=[GoogleSearchTool(), VisitWebpageTool(), calculate_cargo_travel_time],\n",
    "    additional_authorized_imports=[\"pandas\"],\n",
    "    max_steps=20,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "result = agent.run(task)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "result"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We could already improve this a bit by throwing in some dedicated planning steps, and adding more prompting."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "agent.planning_interval = 4\n",
    "\n",
    "detailed_report = agent.run(f\"\"\"\n",
    "You're an expert analyst. You make comprehensive reports after visiting many websites.\n",
    "Don't hesitate to search for many queries at once in a for loop.\n",
    "For each data point that you find, visit the source url to confirm numbers.\n",
    "\n",
    "{task}\n",
    "\"\"\")\n",
    "\n",
    "print(detailed_report)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "detailed_report"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Thanks to these quick changes, we obtained a much more concise report by simply providing our agent a detailed prompt, and giving it planning capabilities!\n",
    "\n",
    "üí∏ But as you can see, the context window is quickly filling up. So **if we ask our agent to combine the results of detailed search with another, it will be slower and quickly ramp up tokens and costs**.\n",
    "\n",
    "‚û°Ô∏è We need to improve the structure of our system."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ‚úåÔ∏è Splitting the task between two agents\n",
    "\n",
    "Multi-agent structures allow to separate memories between different sub-tasks, with two great benefits:\n",
    "- Each agent is more focused on its core task, thus more performant\n",
    "- Separating memories reduces the count of input tokens at each step, thus reducing latency and cost.\n",
    "\n",
    "Let's create a team with a dedicated web search agent, managed by another agent.\n",
    "\n",
    "The manager agent should have plotting capabilities to redact its final report: so let us give it access to additional imports, including `plotly`, and `geopandas` + `shapely` for spatial plotting."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = HfApiModel(\n",
    "    \"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"together\", max_tokens=8096\n",
    ")\n",
    "\n",
    "web_agent = CodeAgent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        GoogleSearchTool(provider=\"serper\"),\n",
    "        VisitWebpageTool(),\n",
    "        calculate_cargo_travel_time,\n",
    "    ],\n",
    "    name=\"web_agent\",\n",
    "    description=\"Browses the web to find information\",\n",
    "    verbosity_level=0,\n",
    "    max_steps=10,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The manager agent will need to do some mental heavy lifting.\n",
    "\n",
    "So we give it the stronger model [DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1), and add a `planning_interval` to the mix."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from smolagents.utils import encode_image_base64, make_image_url\n",
    "from smolagents import OpenAIServerModel\n",
    "\n",
    "\n",
    "def check_reasoning_and_plot(final_answer, agent_memory):\n",
    "    multimodal_model = OpenAIServerModel(\"gpt-4o\", max_tokens=8096)\n",
    "    filepath = \"saved_map.png\"\n",
    "    assert os.path.exists(filepath), \"Make sure to save the plot under saved_map.png!\"\n",
    "    image = Image.open(filepath)\n",
    "    prompt = (\n",
    "        f\"Here is a user-given task and the agent steps: {agent_memory.get_succinct_steps()}. Now here is the plot that was made.\"\n",
    "        \"Please check that the reasoning process and plot are correct: do they correctly answer the given task?\"\n",
    "        \"First list reasons why yes/no, then write your final decision: PASS in caps lock if it is satisfactory, FAIL if it is not.\"\n",
    "        \"Don't be harsh: if the plot mostly solves the task, it should pass.\"\n",
    "        \"To pass, a plot should be made using px.scatter_map and not any other method (scatter_map looks nicer).\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": make_image_url(encode_image_base64(image))},\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    output = multimodal_model(messages).content\n",
    "    print(\"Feedback: \", output)\n",
    "    if \"FAIL\" in output:\n",
    "        raise Exception(output)\n",
    "    return True\n",
    "\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    model=HfApiModel(\"deepseek-ai/DeepSeek-R1\", provider=\"together\", max_tokens=8096),\n",
    "    tools=[calculate_cargo_travel_time],\n",
    "    managed_agents=[web_agent],\n",
    "    additional_authorized_imports=[\n",
    "        \"geopandas\",\n",
    "        \"plotly\",\n",
    "        \"shapely\",\n",
    "        \"json\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "    ],\n",
    "    planning_interval=5,\n",
    "    verbosity_level=2,\n",
    "    final_answer_checks=[check_reasoning_and_plot],\n",
    "    max_steps=15,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let us inspect what this team looks like:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "manager_agent.visualize()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "manager_agent.run(\"\"\"\n",
    "Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128¬∞ N, 74.0060¬∞ W).\n",
    "Also give me some supercar factories with the same cargo plane transfer time. You need at least 6 points in total.\n",
    "Represent this as spatial map of the world, with the locations represented as scatter points with a color that depends on the travel time, and save it to saved_map.png!\n",
    "\n",
    "Here's an example of how to plot and return a map:\n",
    "import plotly.express as px\n",
    "df = px.data.carshare()\n",
    "fig = px.scatter_map(df, lat=\"centroid_lat\", lon=\"centroid_lon\", text=\"name\", color=\"peak_hour\", size=100,\n",
    "     color_continuous_scale=px.colors.sequential.Magma, size_max=15, zoom=1)\n",
    "fig.show()\n",
    "fig.write_image(\"saved_image.png\")\n",
    "final_answer(fig)\n",
    "\n",
    "Never try to process strings using code: when you have a string to read, just print it and you'll see it.\n",
    "\"\"\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I don't know how that went in your run, but in mine, the manager agent skilfully divided tasks given to the web agent in `1. Search for Batman filming locations`, then `2. Find supercar factories`, before aggregating the lists and plotting the map.\n",
    "\n",
    "Let's see what the map looks like by inspecting it directly from the agent state:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "manager_agent.python_executor.state[\"fig\"]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![output map](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/smolagents/output_map.png)"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
