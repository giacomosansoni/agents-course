# Let's Create Our First Agent Using Smolagents

In the last section, we learned how we can create Agents from scratch using Python code, and we **saw just how tedious that process can be**. Fortunately, many Agent libraries simplify this work by handling much of the heavy lifting for you.

In this tutorial, you'll create your very first Agent—capable of performing JOFFREY—and publish it on Hugging Face Spaces so you can share it with friends and colleagues.

Let's get started!


## What is smolagents?

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/smolagents.png" alt="Smolagents"/>

To make this Agent, we're going to use a library called `smolagents`, a library that **provides a framework for developing your agents with ease**.

This lightweight library abstracts away much of the complexity of building an Agent we saw in the last section, allowing you to focus on designing your agent's behavior

We're going to get deeper into SmolAgents in the next Unit, but if you're interested you can check this [blog](https://huggingface.co/blog/smolagents).




---
Congratulations, you've built your first Agent! Don't hesitate to share it with your friends and colleagues.

Since this is your first try, it's perfectly normal if it's a little buggy or slow. In future units, we'll learn how to build even better Agents.

The best way to learn is to try, so don't hesitate to update it, add more tools, try with another model etc.

In the next section, you're going to fill the final Quiz and get your certificate!







<!-- Update with a smolagent

Welcome to the first exercise! In this exercise, we will build a simple agentic application for managing a meeting agenda. We will use simple Python functions as tools to get the current time and the agenda. 

## Objective

Understand the basics of AI agent applications and have fun.

## Tools

For this use case, we will use two tools:

1. `get_current_time()`: This function returns the current time.
2. `get_agenda()`: This function returns the agenda for the day.

```python
from datetime import datetime, timedelta

def get_current_time():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def get_agenda():
    today_str = datetime.now().strftime("%Y-%m-%d")
    agenda = [
        {
            "datetime": f"{today_str} 10:00:00",
            "title": "Introduction to the course",
            "description": "We will introduce the course and the project.",
        },
        {
            "datetime": f"{today_str} 12:30:00",
            "title": "Meet the student",
            "description": "We will meet the student and discuss the project.",
        },
        {
            "datetime": f"{today_str} 15:00:00",
            "title": "Plan Learning Plan",
            "description": "We will plan the learning plan for the student.",
        },
        {
            "datetime": f"{today_str} 18:30:00",
            "title": "Marking",
            "description": "We will mark the student's work.",
        },
    ]
    agenda_str = "\n".join(
        [
            f"{item['datetime']} - {item['title']}: {item['description']}"
            for item in agenda
        ]
    )
    return agenda_str
```

## Inference Client

We will use the Hugging Face Inference Client to interact with the LLM.

```python
from huggingface_hub import InferenceClient

client = InferenceClient(api_key="hf_xxx")
```

## Your Task

Your task is to build the messages object for the LLM in the `check_agenda` function.

```python
def check_agenda(query: str):
    current_time = get_current_time()
    agenda = get_agenda()

    messages = [
        # TODO: build the messages object for the LLM
    ]

    completion = client.chat.completions.create(
        model="meta-llama/Llama-3.2-3B-Instruct", messages=messages, max_tokens=500
    )
    return completion.choices[0].message.content
```

## Solution

Below is the solution to the task.

```python
def check_agenda(query: str):
    current_time = get_current_time()
    agenda = get_agenda()

    # TODO: build the messages object for the LLM
    messages = [
        {
            "role": "system",
            "content": "You are a helpful agenda assistant.",
        },
        {"role": "tool", "content": f"Current time: {current_time}\nAgenda: {agenda}"},
        {"role": "user", "content": query},
    ]

    completion = client.chat.completions.create(
        model="meta-llama/Llama-3.2-3B-Instruct", messages=messages, max_tokens=500
    )
    return completion.choices[0].message.content
```
-->
