# What is Function-Calling?

Function-Calling is a **way for an LLM to take actions on its environment**. It has first been introduced in GPT-4, and was then reproduced in other models.

Just like an Agent, Function-Calling is the capacity for the model to **take an action on it's environment**. But this capacity **is learned by the model**, and relies **less on prompting than other agents techniques**.

If you remember, during the Unit 1, the Agent **didn't learn the Tools**, we just provided the list, and we relied on the fact that the model **was able to generalize on defining a plan using these Tools**. 

While here, **with Function-Calling, the Agent is fine-tuned (trained) on using these Tools**.


## How does the model "learn" to take action?

In Unit 1, the general workflow of an agent. When the user give some tools to thee agent and prompt it with a query, the model will do a cycle of :

1. *Think* : What action(s) do I need to take in order to fulfill the objective.
2. *Act* : Format the action with the correct parameter and stop the generation.
3. *Observe¨ : Get back the result from the execution.

in a "normal" conversation with a model through an API, the conversation is an alternance of user and assistant messages:

```python
conversation = [
    {"role": "user", "content": "I need help with my order"},
    {"role": "assistant", "content": "I'd be happy to help. Could you provide your order number?"},
    {"role": "user", "content": "It's ORDER-123"},
]
```

Function-Calling is adding **new roles to that conversation** ! 

1. One new role for an **Action** 
2. One new role for an **Observation** 

If we take as an example the [Mistral API](https://docs.mistral.ai/capabilities/function_calling/), here what it looks like :


```python
conversation = [
    {
        "role": "user",
        "content": "What's the status of my transaction T1001?"
    },
    {
        "role": "assistant",
        "content": "",
        "function_call": {
            "name": "retrieve_payment_status",
            "arguments": "{\"transaction_id\": \"T1001\"}"
        }
    },
    {
        "role": "tool",
        "name": "retrieve_payment_status",
        "content": "{\"status\": \"Paid\"}"
    },
    {
        "role": "assistant",
        "content": "Your transaction T1001 has been successfully paid."
    }
]
```

> But you said there's a new role for function calls ?

**Yes and no**, in this case and in a lot of different APIs, the model will format the action to take inside an "assistant" message but it will be inside some new **special tokens**.

- `[AVAILABLE_TOOLS]` – Start the list of available tools  
- `[/AVAILABLE_TOOLS]` – End the list of available tools  
- `[TOOL_CALLS]` – Make a call to a tool (i.e., take an "Action")  
- `[TOOL_RESULTS]` – "Observe" the result of the action  
- `[/TOOL_RESULTS]` – End of the observation (i.e., the model can decode again)

We'll talk again about Function-Calling in this course, but if you want to dive deeper you can check [this excellent documentation section](https://docs.mistral.ai/capabilities/function_calling/)

---
Now that we learned what is Function-Calling and how it works, let's **add some Function-Calling capacities to a model that do not have those capacities yet**: **"google/gemma-2-2b-it"** by appending some new special tokens to the model.

To be able to do that, **we need first to understand what's fine-tuning and LoRA**.