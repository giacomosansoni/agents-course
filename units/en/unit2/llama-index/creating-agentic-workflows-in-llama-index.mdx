# Creating agentic workflows in LlamaIndex

A workflow helps you organize your code into simple steps that run one after another.

Such a workflow is created by defining `Steps` which are triggered by `Events`, and themselves emit `Events` to trigger further steps.
By combining steps and events, you can create arbitrarily complex logic flows and make your application more maintainable and easier to understand.
A step can be anything from a single line of code to a complex agent and can have arbitrary inputs and outputs, which are passed around by Events.
As you might have guessed, this strikes a great balance between autonomy of agents while maintaining control over the overall workflow.

So, let's learn how to create a workflow ourselves!

### Creating a Workflow

First things first, let's install the workflow package `pip install llama-index-utils-workflow`.
Now, we can create a single step workflow by defining a class that inherits from `Workflow` and decorating your functions with `@step`.
Note that we also need to add `StartEvent` and `StopEvent` as type hints to the function to ensure that the workflow runs correctly.
```python
from llama_index.core.workflow import StartEvent, StopEvent, Workflow, step

class MyWorkflow(Workflow):
    @step
    async def my_step(self, ev: StartEvent) -> StopEvent:
        # do something here
        return StopEvent(result="Hello, world!")


w = MyWorkflow(timeout=10, verbose=False)
result = await w.run()
```

As you can see, we can now run the workflow by calling `w.run()`.
Let's complicate the flow by adding a second step.
To do so, we need to add an `Event` that is passed between the steps and transfers the output of the first step to the second step.

```python
from llama_index.core.workflow import Event

class FirstEvent(Event):
    first_output: str

class MyWorkflow(Workflow):
    @step
    async def my_first_step(self, ev: StartEvent) -> FirstEvent:
        # do something here
        return FirstEvent(first_output="Hello, world!")

    @step
    async def my_second_step(self, ev: FirstEvent) -> StopEvent:
        # do something here
        return StopEvent(result="Hello, world!")
```

The type hinting is important here, as it ensures that the workflow is executed correctly.
This is also the most powerful part because the type hinting allows us to create branches, loops, joins to facilitate more complex workflows.

Let's show an example of a loop to illustrate the concept.

```python
@step
async def step_one(self, ev: StartEvent | LoopEvent) -> FirstEvent | LoopEvent:
    if random.randint(0, 1) == 0:
        print("Bad thing happened")
        return LoopEvent(loop_output="Back to step one.")
    else:
        print("Good thing happened")
        return FirstEvent(first_output="First step complete.")
```

There is one last cool trick that we will cover in the course, which is the ability to add state to the workflow.
This is useful when you want to keep track of the state of the workflow, so that every step has access to the same state.

```python
from llama_index.core.workflow import Context, StartEvent, StopEvent


@step
async def query(self, ctx: Context, ev: StartEvent) -> StopEvent:
    # retrieve from context
    query = await ctx.get("query")

    # do something with context and event
    val = ...

    # store in context
    await ctx.set("key", val)

    return StopEvent(result=result)
```

Great! Now you know how to create a controllable workflow in LlamaIndex!

> There are some more complex nuances to workflows, which you can learn about in [the LlamaIndex documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/)

However, there is another way to create workflows, which is by using the `AgentWorkflow` class.

### Automating workflows with Multi-Agent Workflows

Instead of manual workflow creation, we can use the **`AgentWorkflow` class to create a multi-agent workflow**.
The `AgentWorkflow` uses Workflow Agents to allow you to create a system of one or more agents that can collaborate and hand off tasks to each other based on their specialized capabilities.
This enables building complex agent systems where different agents handle different aspects of a task.
Instead of importing classes from `llama_index.core.agent`, we will import the agent classes from `llama_index.core.agent.workflow`.
One agent must be designated as the root agent in the `AgentWorkflow` constructor.
When a user message comes in, it is first routed to the root agent. Each agent can then:

- Handle the request directly using their tools
- Hand off to another agent better suited for the task
- Return a response to the user

Let's see how to create a multi-agent workflow.

```python
from llama_index.core.agent.workflow import AgentWorkflow, FunctionAgent, ReActAgent

query_engine_agent_tool = # as defined in the previous section
# Define the agents
multiply_agent = FunctionAgent(
    fn=lambda x, y: x * y,
    name="multiply",
    description="Multiplies two integers",
)
retriever_agent = ReActAgent(
    llm=llm,
    tools=[query_engine_agent_tool],
)
# Create the workflow
workflow = AgentWorkflow(
    agents=[multiply_agent, retriever_agent], root_agent="multiply"
)

# Run the system
response = await workflow.run(user_msg="Can you add 5 and 3?")
```

Before starting the workflow, we can provide an initial state dict that will be available to all agents.
The state is stored in the state key of the workflow context. It will be injected into the state_prompt which augments each new user message.

```python
workflow = AgentWorkflow(
    agents=[...],
    root_agent="root_agent",
    initial_state={"counter": 0},
    state_prompt="Current state: {state}. User message: {msg}",
)
```

Congratulations! You have now mastered the basics of Agents in LlamaIndex! ðŸŽ‰

Let's continue with tackling `LangGraph`! ðŸš€